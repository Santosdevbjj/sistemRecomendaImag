# Imports principais
import sys
import os
sys.path.append("/content/src")  # garante que src seja importável

from models.train import train_model
from models.embedding_model import EmbeddingModel
from utils.io import load_image, list_images
from utils.viz import show_image, show_similar_images

import numpy as np
import torch 

# Pasta do dataset
DATA_DIR = "/content/data/processed"

# Listar todas as imagens
all_images = list_images(DATA_DIR)
print(f"Total de imagens encontradas: {len(all_images)}")

# Mostrar uma imagem de exemplo
show_image(all_images[0], title="Exemplo de imagem") 


# Treinar modelo (ou carregar pré-treinado)
model = train_model(
    data_dir=DATA_DIR,
    epochs=2,  # reduzir para teste rápido no Colab
    save_path="/content/data/models/embedding_model.pth"
) 

# Carregar modelo
embedding_model = EmbeddingModel(backbone="resnet50")
embedding_model.load_state_dict(torch.load("/content/data/models/embedding_model.pth", map_location="cpu"))
embedding_model.eval()

# Escolher algumas imagens de teste
test_images = all_images[:5]
embeddings = [embedding_model.get_embedding(img) for img in test_images]

# Converter para numpy
embeddings_np = np.vstack(embeddings)
print("Embeddings extraídos com sucesso:", embeddings_np.shape) 


import faiss

# Criar índice FAISS
dim = embeddings_np.shape[1]
index = faiss.IndexFlatL2(dim)
index.add(embeddings_np)

# Escolher query
query_idx = 0
D, I = index.search(embeddings_np[query_idx:query_idx+1], k=3)

neighbors_paths = [test_images[i] for i in I[0][1:]]  # descarta a própria query

# Visualizar query e vizinhos
show_similar_images(test_images[query_idx], neighbors_paths) 
